# hls_reports.py
# Code to parse the reports generated by Vivado HLS
import re
import xml.etree.ElementTree as ET
import utils

def read_report_xml(xml_report_filepath):
   tree = ET.parse(xml_report_filepath)
   return tree.getroot()

def GetWorstCaseLatency(report_xml):
   return int(report_xml.find('PerformanceEstimates').find('SummaryOfOverallLatency').find('Worst-caseLatency').text)

def GetCostInfo(layer_spec, report_xml, cost_func):
   # Function for calculating cost. There are different cost functions the user can specify.
   #
   # "Default" cost is the sum of the percentages of each resource in the FPGA that is utilized.
   # This is a common cost function used in similar works. One important caveat is how URAM cost is
   # calculated.
   #
   # First, there is a bug in Vitis HLS 2019.2 where the required URAMs are not doubled when the URAMs
   # are double-buffered for the dataflow pipeline. Therefore I account for the doubling in this function. 
   # TODO: If/when moving to v2020.2, check to see if this is fixed.
   #
   # Second, the HLS reports will show URAMs used for both input and output. But the output of one layer
   # is the input to the next layer. So we don't want to double-count the URAMs. To fix this, only count
   # the input URAMs for each channel. The AXI input layer has no input URAMs.
   #
   # "LUTs only" cost excludes LUT utilization, and "DSP only" only considers DSPs.
   resources = report_xml.find('AreaEstimates').find('Resources')
   available_resources = report_xml.find('AreaEstimates').find('AvailableResources')
   cost = {}
   cost_factors = [('bram', 'BRAM_18K'), ('dsp', 'DSP'), ('ff', 'FF'), ('lut', 'LUT'), ('uram', 'URAM')]
   total_cost = 0.0

   # Calculate adjustment multiplier for URAM cost
   ltype = layer_spec['layer_type']
   if ltype == 'axi_in':
      uram_multiplier = 0
   elif ltype == 'axi_out':
      uram_multiplier = 1
   else:
      estimated_input_urams  = utils.calc_num_urams(layer_spec, 'input')
      estimated_output_urams = utils.calc_num_urams(layer_spec, 'output')
      uram_multiplier = estimated_input_urams / (estimated_input_urams + estimated_output_urams)

   for name, rpt_name in cost_factors:
      resources_utilized = int(resources.find(rpt_name).text) 
      resources_available = int(available_resources.find(rpt_name).text)
      if name == 'uram':
         # Fix URAM cost.
         resources_utilized = resources_utilized * uram_multiplier * 2
      resource_cost = resources_utilized / resources_available
      cost[name] = resource_cost
      total_cost = total_cost + resource_cost

   if cost_func == 'default':
      cost['total'] = total_cost
   elif cost_func == 'no_luts':
      cost['total'] = total_cost - cost['lut']
   elif cost_func == 'dsp_only':
      cost['total'] = cost['dsp']
   else:
      raise Exception('Unrecognized cost function.')

   return cost

# This method is used to parse the human-readable report generated
# for the dataflow pipeline inside the top loop.
# Ideally we wouldn't need to do this and could just parse the XML files,
# but for some reason, the XML files do not list the functions within the 
# dataflow pipeline. Since these functions can potentially vary between
# different implementations of the same layer, it would not be a good idea
# to hardcode them.
#
# This method returns a list of dicts that indicates the latencies of each 
# stage in the pipeline. Stages with a latency of 0 are not reported.
def GetDataflowStageLatencies(dataflow_rpt_filepath):
   stages = []
   stage_names = []
   with open(dataflow_rpt_filepath, 'r') as rpt:
      # Find the line with the word "Module" in it
      for line in rpt:
         if "Module" in line:
            break
      # Skip the next line
      rpt.readline()
      # Now parse lines until we find one that matches "---"
      # For each one, split it on "|" surrounded by whitespace characters (greedy)
      # Index [2] is the module name, index [8] is the worst-case latency.
      for line in rpt:
         if "---" in line:
            break
         tokens = re.split(r'\s*\|\s*', line)
         stage  = tokens[2]
         cycles = int(tokens[8])
         # Skip duplicate accumulation stages
         if re.search('accum_\d_\d', stage) is not None or stage in stage_names:
            continue
         if cycles > 0:
            stages.append({'name': stage, 'latency': cycles})
            stage_names.append(stage)

   longest_stage_cycles = max([s['latency'] for s in stages])
   dataflow_ii = longest_stage_cycles + 1 # Dataflow pipeline incurs 1 cycle overhead
   return stages, dataflow_ii


# Test GetDataflowStageLatencies function
if __name__ == "__main__":
   import sys
   res, dii = GetDataflowStageLatencies(sys.argv[1])
   print(res)
